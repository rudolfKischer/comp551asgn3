{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Classification of Image Data\n",
    "- COMP 551 Winter 2024, Mcgill University\n",
    "- Rudolf Kischer: 260956107\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synopsis\n",
    "- In this miniproject, we will implement a multilayer perceptron from scratch, and use it to classify image data. The goal is to implement a basic neural network and its training algorithm from scratch and get hands-on experience with important decisions that you have to make while training these models. You will also have a chance to experiment with convolutional neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- [Sign Language MNIST](https://www.kaggle.com/datasets/datamunge/sign-language-mnist/data)\n",
    "- Features: 28 x 28 grayscale images of hand symbols (784 pixels/features)\n",
    "- Labels: 24 classes of letters (excludes 9=J and 25=Z because they require motion)\n",
    "- Train: 27,455\n",
    "- Test: 7172 \n",
    "- Most of the images are produced through an alteration of 1704 uncropped color images\n",
    "- These alternations include the following:\n",
    "    - \"To create new data, an image pipeline was used based on ImageMagick and included cropping to hands-only, gray-scaling, resizing, and then creating at least 50+ variations to enlarge the quantity. The modification and expansion strategy was filters ('Mitchell', 'Robidoux', 'Catrom', 'Spline', 'Hermite'), along with 5% random pixelation, +/- 15% brightness/contrast, and finally 3 degrees rotation.\"\n",
    "- CSV format, (label, pixel1, pixel2, ... , pixel784)\n",
    "- <img width=400 src=\"https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/amer_sign3.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com/20240314/auto/storage/goog4_request&X-Goog-Date=20240314T192335Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=5090d6842cb28ba5080a37a44706cfab4cba880c104d7acf1510df2a187f3c644bccde7d786cf964d8704f172a1b288bff914ae767deace400edfbd0610023d7cc6c6e329c2d365dc9f5a81c6bfe641800d6c7ecb500470fb48cabf2b555080be0f07559522be5487e6f3f456e8c20b909a818ffd6eaf2658089c82659443e1df42d0c06956fd5f46d9d1b9dfd6458ab03e47796b278463a2d1ebbeac2328b7ba668662807ce3b138e72afca7e9f29d4d01854d0ed4e8416afc4206787976e861cc0f14d9755542f06ee1a52e71e16a112f7e2e1e53a6136d711f54a64e8ad531c07083108fd034a1bf8cf04a5c9a13f94ca6fa0291fb1c60dc9b7629095b1a9\"/>\n",
    "- <img width=400 src=\"https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/american_sign_language.PNG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com/20240315/auto/storage/goog4_request&X-Goog-Date=20240315T200917Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=208afda814e246ab63f6d5f39436a53bcb0aa69be2ca78290e4caf450a4b47f8ea3fd9686815a4836e37c35682e0cc70c122f52f664ee18fa36407caa91f3f00b3874aa926ca4fab2d2366e114da10cad6014c1e8d978a80a150c45e3b4b5a855756a5d8ac9e1c606674728b5868a48e954329c9b41af9a3a0b912fedecf4d2bca40407add7f87d4c4bd57a423dbb4257b73fe0bf5830b81eadea549a41dd70b47c9acc9150078416f517b2814578506b379aee8543fe99f8e060ac978dd21dfc9dab5d7702a1d16b9ccc330500f9204e43ca21462f6bb3f48a70a70c7445f88a0a02e96a587c4babb965eb12adc6b2ca82e3cd6e91026f5204e93edc8bb82f2\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- To prepare the data for usage we need to:\n",
    "  - download the dataset\n",
    "  - load the dataset\n",
    "  - seperate into X and Y\n",
    "  - vectorize the image data\n",
    "  - Center and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_mnist_sign_language():\n",
    "  kaggle_command = f'kaggle datasets download -d datamunge/sign-language-mnist'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataset(csv_path):\n",
    "  df = pd.read_csv(csv_path)\n",
    "  return df\n",
    "\n",
    "def load_mnist_sign_dataset():\n",
    "  dataset_directory = 'data/archive/'\n",
    "  test_set_path = f'{dataset_directory}/sign_mnist_test/sign_mnist_test.csv'\n",
    "  train_set_path = f'{dataset_directory}/sign_mnist_train/sign_mnist_train.csv'\n",
    "  df_test = pd.read_csv(test_set_path)\n",
    "  df_train = pd.read_csv(train_set_path)\n",
    "  # df_train.info()\n",
    "  # df_test.info()\n",
    "  return df_test, df_train\n",
    "\n",
    "def shape(df):\n",
    "  Y = df['label']\n",
    "  lb = LabelBinarizer()\n",
    "  Y = lb.fit_transform(Y)\n",
    "  X = df.drop(['label'],axis=1)\n",
    "  X = X.values.reshape(-1,28,28,1)\n",
    "  # one hot encode\n",
    "  \n",
    "  return X, Y\n",
    "\n",
    "def standardize_data(X):\n",
    "  # center by subtracting the mean\n",
    "  # divide by the standard deviation\n",
    "  # N X D \n",
    "  # N X W X H X C\n",
    "  # copy the data\n",
    "  X = X.copy()\n",
    "  X = X - X.mean(axis=0)\n",
    "  X = X / X.std(axis=0)\n",
    "  return X\n",
    "\n",
    "def display_image(X, Y, index):\n",
    "  plt.imshow(X[index].reshape(28,28), cmap='gray')\n",
    "  alphanumeric = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "  plt.title(f'{alphanumeric[np.argmax(Y[index])]}')\n",
    "  plt.show()\n",
    "\n",
    "def display_images(X, Y, indices, title=None):\n",
    "  # do a multiplot\n",
    "  # that displays the the first 9 images\n",
    "  # with their labels\n",
    "  fig, ax = plt.subplots(3, 3, figsize=(10,10))\n",
    "  # add title\n",
    "  if title:\n",
    "    fig.suptitle(title)\n",
    "  alphanumeric = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "  for i in range(3):\n",
    "    for j in range(3):\n",
    "      ax[i,j].imshow(X[indices[i*3+j]].reshape(28,28), cmap='gray')\n",
    "      ax[i,j].set_title(f'{indices[i*3+j]}: {alphanumeric[np.argmax(Y[indices[i*3+j]])]}')\n",
    "\n",
    "  \n",
    "\n",
    "test, train = load_mnist_sign_dataset()\n",
    "X_e, Y_e = shape(test)\n",
    "X_t, Y_t = shape(train)\n",
    "\n",
    "display_images(X_e, Y_e, [0,1,2,3,4,5,6,7,8], 'Test Set')\n",
    "display_images(X_t, Y_t, [0,1,2,3,4,5,6,7,8], 'Train Set')\n",
    "\n",
    "\n",
    "# X_e = standardize_data(X_e)\n",
    "X_t = standardize_data(X_t)\n",
    "\n",
    "#display first 5 images\n",
    "# display_images(X_e, Y_e, [0,1,2,3,4,5,6,7,8], 'Test Set Standardized')\n",
    "display_images(X_t, Y_t, [0,1,2,3,4,5,6,7,8], 'Train Set Standardized')\n",
    "\n",
    "# print the dimensions\n",
    "print(f'Test Set: X:{X_e.shape} Y:{Y_e.shape}')\n",
    "print(f'Train Set: X:{X_t.shape} Y:{Y_t.shape}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- We will be implementing a deep multi layered perceptron\n",
    "- We want it to be custimizable for different depths and breadths as well as activation functions for experimentations\n",
    "- We will also want to implement convolutional layers as well to test the performance increase\n",
    "- Each model will be composed of multiple layers, each which has a forward and backward function to update the weights of that layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "  return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "  return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def softmax(Z):\n",
    "  expZ = np.exp(Z - np.max(Z))\n",
    "  return expZ / expZ.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 1: MLP Layer Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 2: MLP activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 3: Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 4: Convultional Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 5: Optimizing MLP Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 6: Report Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results And Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
